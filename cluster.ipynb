{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import supervised\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def accuracy(labels_true, labels_pred):\n",
    "    labels_true, labels_pred = supervised.check_clusterings(labels_true, labels_pred)\n",
    "    # labels_true : int array with ground truth labels, shape = [n_samples]\n",
    "    # labels_pred : int array with estimated labels, shape = [n_samples]\n",
    "    value = supervised.contingency_matrix(labels_true, labels_pred)\n",
    "    # value : array of shape [n, n] whose (i, j)-th entry is the number of samples in true class i and in predicted class j\n",
    "    [r, c] = linear_sum_assignment(-value)\n",
    "    return value[r, c].sum() / len(labels_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mason Cole\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Flatten, Activation, add\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras import backend as K\n",
    "\n",
    "from resnet_keras import resnet152_model\n",
    "\n",
    "weights_path = 'resnet_data/resnet152_weights_tf.h5'\n",
    "\n",
    "model = resnet152_model(weights_path)\n",
    "sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "layer_name = 'res5a_relu'\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "def get_labels_from_file(data_name):\n",
    "    mat = scipy.io.loadmat('data/' + data_name + '-' + 'train')\n",
    "    return np.squeeze(mat['labels_train'])\n",
    "\n",
    "def get_resnet_features_from_file(data_name, train=True):\n",
    "    \n",
    "    mat = scipy.io.loadmat('data/' + data_name + '-' + ('train.mat' if train else 'test.mat'))\n",
    "    \n",
    "    images_name = 'images_' + ('train' if train else 'test')\n",
    "    \n",
    "    x = np.reshape(np.transpose(np.repeat(mat[images_name][:,:, np.newaxis],3, axis=2), (1, 0, 2)), (-1, 28, 28, 3))\n",
    "#     x = x * 256 - 128\n",
    "    \n",
    "    large_images = np.array([scipy.misc.imresize(scipy.misc.imrotate(image, -90), size=(224,224), interp='bilinear') for image in x])\n",
    "\n",
    "    \n",
    "    \n",
    "    intermediate_output = intermediate_layer_model.predict(large_images)\n",
    "    return np.mean(intermediate_output, (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intermediate_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-74687980c768>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBirch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'intermediate_output' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn.cluster\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n",
    "\n",
    "kmeans = sklearn.cluster.Birch(n_clusters=5).fit_predict(np.squeeze(np.mean(intermediate_output, (1,2))))\n",
    "accuracy(kmeans, np.reshape(mat['labels_train'],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('digits.csv', kmeans + 1, fmt='%i', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mat = scipy.io.loadmat('data/digits-test.mat')\n",
    "feat = mat['fea_hog_test']\n",
    "\n",
    "kmeans = sklearn.cluster.Birch(n_clusters=5, threshold=0.7).fit_predict(np.transpose(feat))\n",
    "np.savetxt('digits.csv', kmeans + 1, fmt='%i', delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "filename = 'objects'\n",
    "clusters = sklearn.cluster.Birch(n_clusters=5, threshold=0.7, branching_factor=5000).fit_predict(get_resnet_features_from_file(filename, 'test'))\n",
    "\n",
    "print(accuracy(get_labels_from_file(filename), clusters))\n",
    "np.savetxt(filename + '.csv', clusters + 1, fmt='%i', delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
