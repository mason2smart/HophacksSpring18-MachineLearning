{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import supervised\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def accuracy(labels_true, labels_pred):\n",
    "    labels_true, labels_pred = supervised.check_clusterings(labels_true, labels_pred)\n",
    "    # labels_true : int array with ground truth labels, shape = [n_samples]\n",
    "    # labels_pred : int array with estimated labels, shape = [n_samples]\n",
    "    value = supervised.contingency_matrix(labels_true, labels_pred)\n",
    "    # value : array of shape [n, n] whose (i, j)-th entry is the number of samples in true class i and in predicted class j\n",
    "    [r, c] = linear_sum_assignment(-value)\n",
    "    return value[r, c].sum() / len(labels_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mason Cole\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Flatten, Activation, add\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras import backend as K\n",
    "\n",
    "from resnet_keras import resnet152_model\n",
    "\n",
    "# ResNet weights after pretraining on ImageNet\n",
    "weights_path = 'resnet_data/resnet152_weights_tf.h5'\n",
    "\n",
    "# ResNet with 152 layers, pretrained on ImageNet\n",
    "model = resnet152_model(weights_path)\n",
    "# SGD optimizer - not important since we aren't training this model\n",
    "sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Extract features from one of the final ResBlocks in the ResNet\n",
    "layer_name = 'avg_pool'\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "def get_labels_from_file(data_name):\n",
    "    mat = scipy.io.loadmat('data/' + data_name + '-' + 'train')\n",
    "    return np.squeeze(mat['labels_train'])\n",
    "\n",
    "def get_resnet_features_from_file(data_name, train=True):\n",
    "    \n",
    "    mat = scipy.io.loadmat('data/' + data_name + '-' + ('train.mat' if train else 'test.mat'))\n",
    "    \n",
    "    images_name = 'images_' + ('train' if train else 'test')\n",
    "    \n",
    "    x = np.reshape(np.transpose(np.repeat(mat[images_name][:,:, np.newaxis],3, axis=2), (1, 0, 2)), (-1, 28, 28, 3))\n",
    "    # Normalization of input to ResNet\n",
    "#     x = x * 256\n",
    "#     x -= np.mean(x)\n",
    "    \n",
    "    large_images = np.array([scipy.misc.imresize(scipy.misc.imrotate(image, -90), size=(224,224), interp='bilinear') for image in x])\n",
    "    intermediate_output = intermediate_layer_model.predict(large_images)\n",
    "    # Average over spatial components of feature activations\n",
    "    return np.mean(intermediate_output, (1,2))\n",
    "#     return intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "\n",
    "# Run Birch clustering on MNIST HOG features\n",
    "# MNIST is much simpler than CIFAR-10, so HOG is sufficient\n",
    "\n",
    "mat = scipy.io.loadmat('data/digits-test.mat')\n",
    "feat = mat['fea_hog_test']\n",
    "\n",
    "thresholds = []\n",
    "\n",
    "# for t in np.random.uniform(0.69,.85,[100]):\n",
    "clusters = sklearn.cluster.Birch(n_clusters=5, threshold=0.7).fit_predict(np.transpose(feat))\n",
    "# print(t, ' ', accuracy(get_labels_from_file('digits'), clusters))\n",
    "# thresholds.append((t, accuracy(get_labels_from_file('digits'), clusters)))\n",
    "np.savetxt('digits.csv', clusters + 1, fmt='%i', delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.948041   14.744697   -7.652679 ]\n",
      " [-22.075785   -0.9811244  -5.2749605]\n",
      " [ -1.0242753   7.7488575  14.418346 ]\n",
      " ...\n",
      " [  8.497024   10.989828    2.6422594]\n",
      " [-16.34447     2.581515   -9.9346075]\n",
      " [ 17.65837     0.9501796  -2.8437228]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.manifold\n",
    "f = sklearn.manifold.TSNE(n_components=3, init='pca').fit_transform(np.transpose(feat))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2092\n"
     ]
    }
   ],
   "source": [
    "clusters = sklearn.cluster.Birch(n_clusters=5, threshold=0.7).fit_predict(f)\n",
    "print(accuracy(get_labels_from_file('digits'), clusters))\n",
    "np.savetxt('digits.csv', clusters + 1, fmt='%i', delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mason Cole\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: `imrotate` is deprecated!\n",
      "`imrotate` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.rotate`` instead.\n",
      "C:\\Users\\Mason Cole\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "# For CIFAR-10, run Birch clustering on extracted features from ResNet trained on ImageNet.\n",
    "\n",
    "filename = 'objects'\n",
    "\n",
    "resnet_features = get_resnet_features_from_file(filename, False)\n",
    "\n",
    "import sklearn.decomposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced_features = sklearn.decomposition.PCA(10).fit_transform(resnet_features)\n",
    "\n",
    "reduced_features = sklearn.manifold.TSNE(n_components=3, init='pca').fit_transform(resnet_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2228\n"
     ]
    }
   ],
   "source": [
    "clusters = sklearn.cluster.Birch(n_clusters=5, threshold=0.65).fit_predict(reduced_features)\n",
    "\n",
    "# clusters = sklearn.cluster.MiniBatchKMeans(n_clusters=5, batch_size=33).fit_predict(resnet_features)\n",
    "\n",
    "# clusters = sklearn.cluster.KMeans(n_clusters=5).fit_predict(reduced_features)\n",
    "\n",
    "# If testing, print accuracy\n",
    "print(accuracy(get_labels_from_file(filename), clusters))\n",
    "np.savetxt(filename + '.csv', clusters + 1, fmt='%i', delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = sklearn.cluster.Birch(n_clusters=5, threshold=0.7).fit_predict(reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: after getting 0.8226 average accuracy: do a hyperparameter grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.615\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy(get_labels_from_file(filename), clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
