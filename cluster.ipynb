{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import supervised\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def accuracy(labels_true, labels_pred):\n",
    "    labels_true, labels_pred = supervised.check_clusterings(labels_true, labels_pred)\n",
    "    # labels_true : int array with ground truth labels, shape = [n_samples]\n",
    "    # labels_pred : int array with estimated labels, shape = [n_samples]\n",
    "    value = supervised.contingency_matrix(labels_true, labels_pred)\n",
    "    # value : array of shape [n, n] whose (i, j)-th entry is the number of samples in true class i and in predicted class j\n",
    "    [r, c] = linear_sum_assignment(-value)\n",
    "    return value[r, c].sum() / len(labels_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mason Cole\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Flatten, Activation, add\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras import backend as K\n",
    "\n",
    "from resnet_keras import resnet152_model\n",
    "\n",
    "weights_path = 'resnet_data/resnet152_weights_tf.h5'\n",
    "\n",
    "model = resnet152_model(weights_path)\n",
    "sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "layer_name = 'res5a_relu'\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "def get_labels_from_file(data_name):\n",
    "    mat = scipy.io.loadmat('data/' + data_name + '-' + 'train')\n",
    "    return np.squeeze(mat['labels_train'])\n",
    "\n",
    "def get_resnet_features_from_file(data_name, train=True):\n",
    "    \n",
    "    mat = scipy.io.loadmat('data/' + data_name + '-' + ('train.mat' if train else 'test.mat'))\n",
    "    \n",
    "    images_name = 'images_' + ('train' if train else 'test')\n",
    "    \n",
    "    x = np.reshape(np.transpose(np.repeat(mat[images_name][:,:, np.newaxis],3, axis=2), (1, 0, 2)), (-1, 28, 28, 3))\n",
    "#     x = x * 256 - 128\n",
    "    \n",
    "    large_images = np.array([scipy.misc.imresize(scipy.misc.imrotate(image, -90), size=(224,224), interp='bilinear') for image in x])\n",
    "\n",
    "    \n",
    "    \n",
    "    intermediate_output = intermediate_layer_model.predict(large_images)\n",
    "    return np.mean(intermediate_output, (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "\n",
    "mat = scipy.io.loadmat('data/digits-test.mat')\n",
    "feat = mat['fea_hog_test']\n",
    "\n",
    "clusters = sklearn.cluster.Birch(n_clusters=5, threshold=0.7).fit_predict(np.transpose(feat))\n",
    "np.savetxt('digits.csv', clusters + 1, fmt='%i', delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mason Cole\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `imrotate` is deprecated!\n",
      "`imrotate` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.rotate`` instead.\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Mason Cole\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2172\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "filename = 'objects'\n",
    "clusters = sklearn.cluster.Birch(n_clusters=5, threshold=0.7, branching_factor=5000).fit_predict(get_resnet_features_from_file(filename, False))\n",
    "\n",
    "print(accuracy(get_labels_from_file(filename), clusters))\n",
    "np.savetxt(filename + '.csv', clusters + 1, fmt='%i', delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
